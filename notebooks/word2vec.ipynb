{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDqfNwhTyF3-",
        "outputId": "d9b28c0f-191f-4c76-8353-de24da3eb1f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMOzwJUuyccw",
        "outputId": "3349d08e-70f0-42b5-cdb2-b0bf35f63f1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy gensim\n",
        "!pip install numpy gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnhnFxxaykto",
        "outputId": "bf284265-f499-4860-bbf3-456831c2f9d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy-1.26.4.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: gensim 4.3.3\n",
            "Uninstalling gensim-4.3.3:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/gensim-4.3.3.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/gensim/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled gensim-4.3.3\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy, gensim\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IJ4ak66jwR1e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./bbc_encoded.csv')"
      ],
      "metadata": {
        "id": "4JYTBuK4x-Oa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  text = re.sub(r'[^ \\nA-Za-z0-9À-ÖØ-öø-ÿ/]+', '', text)\n",
        "  text = re.sub(r'[\\\\/×\\^\\]\\[÷]', '', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "atJ8YeJfy8cL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lower_case(text):\n",
        "  text = text.lower()\n",
        "  return text"
      ],
      "metadata": {
        "id": "5dOOxK7pzG6a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIhJVVg0zyX-",
        "outputId": "8e281255-401d-44c4-d4f0-63bc85f0e923"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_list = stopwords.words(\"english\")\n",
        "def remover(text):\n",
        "  text_tokens = text.split(\" \")\n",
        "  final_list = [word for word in text_tokens if not word in stopwords_list]\n",
        "  text = ' '.join(final_list)\n",
        "  return text"
      ],
      "metadata": {
        "id": "Bv7-x8aXzKiG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text\"] = df[\"text\"].astype(str)\n",
        "df[\"text\"] = df[\"text\"].apply(lower_case)\n",
        "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
        "df[\"text\"] = df[\"text\"].apply(remover)"
      ],
      "metadata": {
        "id": "qp_JShf12J-9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_w2vdf(df):\n",
        "    w2v_df = pd.DataFrame(df[\"text\"]).values.tolist()\n",
        "    for i in range(len(w2v_df)):\n",
        "        w2v_df[i] = w2v_df[i][0].split(\" \")\n",
        "    return w2v_df"
      ],
      "metadata": {
        "id": "es1CwTEszmg3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_w2v(w2v_df):\n",
        "    cores = multiprocessing.cpu_count()  # Using multiple cores for training\n",
        "    w2v_model = Word2Vec(min_count=4,\n",
        "                         window=4,\n",
        "                         vector_size=300,  # size is deprecated in favor of vector_size\n",
        "                         alpha=0.03,\n",
        "                         min_alpha=0.0007,\n",
        "                         sg=1,  # Skip-gram model\n",
        "                         workers=cores-1)\n",
        "\n",
        "    w2v_model.build_vocab(w2v_df, progress_per=10000)\n",
        "    w2v_model.train(w2v_df, total_examples=w2v_model.corpus_count, epochs=100, report_delay=1)\n",
        "    return w2v_model"
      ],
      "metadata": {
        "id": "Lg7X4wh10WxY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_df = get_w2vdf(df)\n",
        "w2v_model = train_w2v(w2v_df)"
      ],
      "metadata": {
        "id": "7Hx1tR120qy-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_to_vec(sentence_tokens, model, dim):\n",
        "    vectors = [model.wv[word] for word in sentence_tokens if word in model.wv]\n",
        "    if not vectors:\n",
        "        return np.zeros(dim)\n",
        "    return np.mean(vectors, axis=0)"
      ],
      "metadata": {
        "id": "Ff9rdUwD2DmR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "sentence_vectors = np.array([sentence_to_vec(sentence, w2v_model, embedding_dim) for sentence in w2v_df])"
      ],
      "metadata": {
        "id": "UI-xBoXQ2rZ0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"sentence_vectors.npy\", sentence_vectors)\n",
        "print(\"Saved sentence vectors to 'sentence_vectors.npy' with shape:\", sentence_vectors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt1E5u8T2tRR",
        "outputId": "1179aba5-43c0-4825-bafb-5987c0924508"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved sentence vectors to 'sentence_vectors.npy' with shape: (2127, 300)\n"
          ]
        }
      ]
    }
  ]
}